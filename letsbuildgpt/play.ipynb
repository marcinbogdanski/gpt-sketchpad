{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5257ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c302a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea401b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06804eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f435a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std grows inside the residual stream\n",
    "import torch\n",
    "x = torch.zeros(768)\n",
    "n = 100  # layers\n",
    "for i in range(n):\n",
    "    x += n**-0.5 * torch.randn(768)\n",
    "\n",
    "print(x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LRScheduler:\n",
    "    def __init__(self, max_lr, min_lr, warmup_steps, max_steps):\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_steps = max_steps\n",
    "    def get_lr(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return self.max_lr * (step+1) / self.warmup_steps\n",
    "        elif self.warmup_steps <= step < self.max_steps:\n",
    "            decay_ratio = (step-self.warmup_steps) / (self.max_steps-self.warmup_steps)\n",
    "            cf = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "            return self.min_lr + cf * (self.max_lr - self.min_lr)\n",
    "        else:\n",
    "            return self.min_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb516d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = LRScheduler(0.5, 0.1, 100, 1000)\n",
    "\n",
    "X = list(range(1100))\n",
    "Y = [lr_sched.get_lr(x) for x in X]\n",
    "\n",
    "plt.plot(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14c45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-sketchpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
