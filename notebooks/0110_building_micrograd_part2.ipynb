{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4ec80d",
   "metadata": {},
   "source": [
    "# Neural Networks: Zero to Hero\n",
    "\n",
    "Video:\n",
    "\n",
    "https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ\n",
    "\n",
    "Reference notebook:\n",
    "\n",
    "https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/micrograd/micrograd_lecture_second_half_roughly.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155c1e7",
   "metadata": {},
   "source": [
    "# Part 1: Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b906420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, label=\"\", _in=(), _op=\"\"):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self._inputs = list(_in)\n",
    "        self._operation = _op\n",
    "        self._grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        res = Value(data=self.data+other.data, _in=(self, other), _op=\"+\")\n",
    "        def backward():\n",
    "            self._grad += 1.0 * res._grad\n",
    "            other._grad += 1.0 * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return Value(other) + self\n",
    "        \n",
    "    def __sub__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        res = Value(data=self.data-other.data, _in=(self, other), _op=\"-\")\n",
    "        def backward():\n",
    "            self._grad += 1.0 * res._grad\n",
    "            other._grad += -1.0 * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return Value(other) - self\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        res = Value(data=self.data*other.data, _in=(self, other), _op=\"*\")\n",
    "        def backward():\n",
    "            self._grad += other.data * res._grad\n",
    "            other._grad += self.data * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return Value(other) * self\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        res = Value(data=self.data/other.data, _in=(self, other), _op=\"/\")\n",
    "        def backward():\n",
    "            self._grad += (1.0 / other.data) * res._grad\n",
    "            other._grad += (-self.data / other.data**2) * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return Value(other) / self\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float))\n",
    "\n",
    "        x = self.data\n",
    "        o = x**other\n",
    "\n",
    "        res = Value(data=o, _in=(self,), _op=\"pow\")\n",
    "        def backward():\n",
    "            self._grad = (other * x**(other-1.0)) * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        o = (math.exp(2*x) - 1.0) / (math.exp(2*x) + 1)\n",
    "        res = Value(o, _in=(self,), _op=\"tanh\")\n",
    "        def backward():\n",
    "            self._grad += (1.0 - res.data**2) * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "\n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        o = math.exp(x)\n",
    "        res = Value(o, _in=(self,), _op=\"exp\")\n",
    "        def backward():\n",
    "            self._grad += o * res._grad\n",
    "        res._backward = backward\n",
    "        return res\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(l={self.label} d={self.data:.4f}, g={self._grad:.4f})\"\n",
    "    \n",
    "    def topo_sort(self):\n",
    "        # Topological sort\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for inp in v._inputs:\n",
    "                    build(inp)\n",
    "                topo.append(v)\n",
    "        build(self)\n",
    "        return topo\n",
    "    \n",
    "    def print_topo(self):\n",
    "        topo = self.topo_sort()\n",
    "        for node in reversed(topo):\n",
    "            print(node)\n",
    "\n",
    "    \n",
    "    def backward(self):\n",
    "        topo = self.topo_sort()        \n",
    "        self._grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        topo = self.topo_sort()\n",
    "        self._grad = 0.0\n",
    "        for node in topo:\n",
    "            node._grad = 0.0\n",
    "\n",
    "    def check_grad(self):\n",
    "        topo = self.topo_sort()\n",
    "        \n",
    "        result = {\"grad_is_zero\": 0, \"grad_non_zero\": 0}\n",
    "        for node in topo:\n",
    "            if node._grad == 0.0:\n",
    "                result[\"grad_is_zero\"] += 1\n",
    "            else:\n",
    "                # print(f\"Grad for {node.label} is: {node._grad}\")\n",
    "                result[\"grad_non_zero\"] += 1\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "print(\"a+2\", a + 2)\n",
    "print(\"2+a\", 2 + a)\n",
    "print(\"a-2\", a - 2)\n",
    "print(\"2-a\", 2 - a)\n",
    "print(\"a*2\", a * 2)\n",
    "print(\"2*a\", 2 * a)\n",
    "print(\"a/2\", a / 2)\n",
    "print(\"2/a\", 2 / a)\n",
    "\n",
    "print(\"a.exp()\", a.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2089fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def build_dot_graph(root_node):\n",
    "    def add_inputs(parent_node, all_nodes):\n",
    "        if parent_node not in all_nodes:\n",
    "            all_nodes.add(parent_node)\n",
    "            for input_node in parent_node._inputs:\n",
    "                add_inputs(input_node, all_nodes)\n",
    "\n",
    "    all_nodes = set()\n",
    "    add_inputs(root_node, all_nodes)\n",
    "\n",
    "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})\n",
    "    for node in all_nodes:\n",
    "        node_label=f'{{ {node.label} ({node._operation}) | {{ d={node.data:.4f} | g={node._grad:.4f} }}}}'\n",
    "\n",
    "        dot.node(str(id(node)), node_label, shape=\"record\")\n",
    "\n",
    "        if node._inputs:\n",
    "            op_node_id = str(id(node))+'_'+node._operation\n",
    "            dot.node( op_node_id, label=node._operation )\n",
    "            dot.edge(op_node_id, str(id(node)))\n",
    "            for input_node in node._inputs:\n",
    "                dot.edge(str(id(input_node)), op_node_id)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "# Weights\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "# Bias\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "# Forward pass\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1x2w2'\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'\n",
    "\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f284a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value(l=o d=0.7071, g=1.0000)\n",
    "# Value(l=n d=0.8814, g=0.5000)\n",
    "# Value(l=b d=6.8814, g=0.5000)\n",
    "# Value(l=x1w1x2w2 d=-6.0000, g=0.5000)\n",
    "# Value(l=x2w2 d=0.0000, g=0.5000)\n",
    "# Value(l=w2 d=1.0000, g=0.0000)\n",
    "# Value(l=x2 d=0.0000, g=0.5000)\n",
    "# Value(l=x1w1 d=-6.0000, g=0.5000)\n",
    "# Value(l=w1 d=-3.0000, g=1.0000)\n",
    "# Value(l=x1 d=2.0000, g=-1.5000)\n",
    "o.print_topo()\n",
    "\n",
    "build_dot_graph(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "# Weights\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "# Bias\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "# Forward pass\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1x2w2'\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "\n",
    "e = (2*n).exp();  e.label = 'e'\n",
    "o = (e - 1) / (e + 1); o.label = 'o'\n",
    "\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value(l=o d=0.7071, g=1.0000)\n",
    "# Value(l= d=6.8284, g=-0.1036)\n",
    "# Value(l= d=1.0000, g=-0.1036)\n",
    "# Value(l= d=4.8284, g=0.1464)\n",
    "# Value(l= d=1.0000, g=-0.1464)\n",
    "# Value(l=e d=5.8284, g=0.0429)\n",
    "# Value(l= d=1.7627, g=0.2500)\n",
    "# Value(l=n d=0.8814, g=0.5000)\n",
    "# Value(l=b d=6.8814, g=0.5000)\n",
    "# Value(l=x1w1x2w2 d=-6.0000, g=0.5000)\n",
    "# Value(l=x2w2 d=0.0000, g=0.5000)\n",
    "# Value(l=w2 d=1.0000, g=0.0000)\n",
    "# Value(l=x2 d=0.0000, g=0.5000)\n",
    "# Value(l=x1w1 d=-6.0000, g=0.5000)\n",
    "# Value(l=w1 d=-3.0000, g=1.0000)\n",
    "# Value(l=x1 d=2.0000, g=-1.5000)\n",
    "# Value(l= d=2.0000, g=0.2203)\n",
    "o.print_topo()\n",
    "\n",
    "build_dot_graph(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7013db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(0.0, requires_grad=True)\n",
    "w1 = torch.tensor(-3.0, requires_grad=True)\n",
    "w2 = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(6.8813735870195432, requires_grad=True)\n",
    "n = x1*w1 + x2*w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "\n",
    "print(f\"x1.grad = {x1.grad.item():.4f}\")\n",
    "print(f\"x2.grad = {x2.grad.item():.4f}\")\n",
    "print(f\"w1.grad = {w1.grad.item():.4f}\")\n",
    "print(f\"w2.grad = {w2.grad.item():.4f}\")\n",
    "print(f\"b.grad = {b.grad.item():.4f}\")\n",
    "\n",
    "# 0.7071067094802856\n",
    "# x1.grad = -1.5000\n",
    "# x2.grad = 0.5000\n",
    "# w1.grad = 1.0000\n",
    "# w2.grad = 0.0000\n",
    "# b.grad = 0.5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5464f2",
   "metadata": {},
   "source": [
    "# Part 2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2228784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, nin, label=\"\"):\n",
    "        self.label = label\n",
    "        self.weights = []\n",
    "        for i in range(nin):\n",
    "            val = Value(random.uniform(-1.0, 1.0), f'{self.label}_w{i}')\n",
    "            self.weights.append(val)\n",
    "        self.bias = Value(random.uniform(-1.0, 1.0), f'{self.label}_b')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        assert all(isinstance(i, (int, float, Value)) for i in inputs)\n",
    "        activation = sum((x * w for x, w in zip(inputs, self.weights)), start=self.bias)\n",
    "        output = activation.tanh()\n",
    "        return output\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.bias]\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, nin, nout, label=\"\"):\n",
    "        self.label = label\n",
    "        self.neurons = []\n",
    "        for i in range(nout):\n",
    "            neuron = Neuron(nin, label=f\"{self.label}_n{i}\")\n",
    "            self.neurons.append(neuron)\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        assert all(isinstance(i, (int, float, Value)) for i in inputs)\n",
    "        results = []\n",
    "        for neuron in self.neurons:\n",
    "            results.append(neuron(inputs))\n",
    "        return results\n",
    "    \n",
    "    def parameters(self):\n",
    "        result = []\n",
    "        for neuron in self.neurons:\n",
    "            result.extend(neuron.parameters())\n",
    "        return result\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, nin, dims):\n",
    "        assert isinstance(nin, int)\n",
    "        assert isinstance(dims, list)\n",
    "        assert all(isinstance(d, int) for d in dims)\n",
    "        self.layers = []\n",
    "        all_dims = [nin] + dims\n",
    "\n",
    "        for i in range(len(all_dims)-1):\n",
    "            in_dim = all_dims[i]\n",
    "            out_dim = all_dims[i+1]\n",
    "            layer = Layer(in_dim, out_dim, label=f\"l{i}\")\n",
    "            self.layers.append(layer)\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            inputs = layer(inputs)\n",
    "\n",
    "        if len(inputs) == 1:\n",
    "            return inputs[0]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def parameters(self):\n",
    "        result = []\n",
    "        for layer in self.layers:\n",
    "            result.extend(layer.parameters())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91385db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "]\n",
    "Y = [1.0, -1.0, -1.0, 1.0]  # targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "mlp = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Predictions\n",
    "ypred = [mlp(x) for x in X]\n",
    "\n",
    "# [0.6994093620224068, 0.5026295816615511, 0.6931545900944501, 0.8755224728708613]\n",
    "print([yp.data for yp in ypred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ee788",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    # Forward pass\n",
    "    for p in mlp.parameters():\n",
    "        p._grad = 0.0\n",
    "\n",
    "    ypred = [mlp(x) for x in X]\n",
    "\n",
    "    loss = sum((yout-y)**2 for yout, y in zip(ypred, Y))\n",
    "    print(loss.data)\n",
    "\n",
    "    assert loss.check_grad()['grad_non_zero'] == 0\n",
    "\n",
    "    # Backward Pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer Update\n",
    "    for p in mlp.parameters():\n",
    "        p.data += -1.0 * 0.12 * p._grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d021a4",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```bash\n",
    "5.230517512042234\n",
    "3.8535617226895393\n",
    "3.9171389480837893\n",
    "1.1416064377049708\n",
    "1.924079918586684\n",
    "3.812200468372784\n",
    "3.481375033842076\n",
    "1.580216893836423\n",
    "0.5856976470695008\n",
    "0.052233808841902554\n",
    "0.04550309897751743\n",
    "0.04052386585920299\n",
    "0.03661536505330471\n",
    "0.03342919066295122\n",
    "0.030763809968969658\n",
    "0.028491843935593043\n",
    "0.026527308067071865\n",
    "0.024809204513010157\n",
    "0.023292578820850944\n",
    "0.021943297412743534\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c595cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1.0, -1.0, -1.0, 1.0]\n",
    "# [0.9279139635559236, -0.9607378181994956, -0.9045175890704561, 0.9219712165552181]\n",
    "print([y for y in Y])\n",
    "print([yp.data for yp in ypred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86240421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d38aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a189e28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-sketchpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
